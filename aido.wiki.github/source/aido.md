# aido package

## Submodules

## aido.interface module

### *class* aido.interface.UserInterfaceBase

Bases: `_UserInterfaceBase`

#### *abstract* simulate(parameter_dict_path, sim_output_path)

This method must be implemented

Starts the simulation process. We recommend starting a container and passing the arguments
from the command line.

Open the parameter dict using:
:rtype: `None`

> parameter_dict = json.load(parameter_dict_path)

Access its items by name and the key ‘current_value’:

> foo_value = parameter_dict[“foo”][“current_value]

The simulation should output exactly one file, which must be saved at ‘sim_output_path’. You
are free to choose the output format of the simulation (e.g. root file)

* **Parameters:**
  * **parameter_dict_path** (*str*) – The path to the parameter dictionary file.
  * **sim_output_path** (*str*) – The path to save the simulation output.

#### *abstract* merge(parameter_dict_file_paths, simulation_file_paths, reco_input_path)

This method must be implemented

This method must merge the parameter dicts and the simulation outputs into a single file.
Its file path will be passed by the scheduler to the ‘reconstruct’ method as the first
argument (‘reco_input_path’). You are free to choose the file format of ‘reco_input_path’.

* **Return type:**
  `None`
* **Parameters:**
  * **parameter_dict_file_paths** (*List* *[**str* *]*) – List of the simulation parameter dictionary paths
  * **simulation_file_paths** (*List* *[**str* *]*) – List of the simulation output paths
  * **reco_input_path** (*str*) – Path for the merged file created by this method.

#### *abstract* reconstruct(reco_input_path, reco_output_path, is_validation=False)

This method must be implemented

Start your reconstruction algorithm here. We recommend using a container and starting the
reconstruction from the command line.

* **Return type:**
  `None`
* **Parameters:**
  * **reco_input_path** (*str*) – Path of the input file for your reconstruction process. It is the same
    path as the output of the ‘merge’ method.
  * **reco_output_path** (*str*) – Path of the output file generated by your reconstruction process. Since
    this file interfaces with the AIDO Optimizer, it must have a specific format detailed in the
    following.
  * **is_validation** (*bool*) – Useful to define a distinct behavior for regular reconstruction and for
    evaluation.

Output file format (IMPORTANT):
: The output file generated by this method must be a parquet file of a pandas.DataFrame.

#### constraints(parameter_dict, parameter_dict_as_tensor)

This method is optional

Use this method to compute additional constraints such as cost or dimensions using pytorch. The resulting
Tensor must be one-dimensional and include gradients.

* **Return type:**
  `None` | `Tensor`

#### plot(parameter_dict)

This method is optional

Use this method to execute code after each iteration. This can be anything used to track the
progress of the Optimization process.

* **Return type:**
  `None`

#### loss(y, y_pred)

This method is optional

Use this method to compute the loss of the internal Optimizer. This must be an equivalent
implementation to your reconstruction loss.

* **Return type:**
  `Tensor`

## aido.main module

The AI Detector Optimization framework (AIDO) is a tool for learning the optimal
design of particle physics detectors. By interpolating the results of simulations
with slightly different geometries, it can iteratively find the best set of detector
parameters.

This framework fragments the workflow into [b2luigi]([https://b2luigi.readthedocs.io/en/stable/index.html](https://b2luigi.readthedocs.io/en/stable/index.html))
Tasks for parallel simulations and the training of ML models on GPUs.

In order to use this framework, you need:

> 1. A simulation software. Any tool that can produce relevant information with which to
>    gauge the performance of your detector. Explicitly, AIDO was developed with Geant4
>    simulations in mind, but there is no hard constraint on this. The details about
>    the requirements for you simulation software are explained further
> 2. A reconstruction algorithm. This can be any piece of code that computes a loss function
>    based on expected versus true Monte Carlo information. In essence, AIDO works by
>    optimizing the loss you provide with this algorithm.

A parameter is defined as any value that can be adjusted in your simulation software. It
is the goal of AIDO to perform a hyperparameter optimization on this parameter to improve
the loss calculated by the reconstruction algorithm. The :class: aido.SimulationParameter
object is the basic building block for a parameter. It keeps track of the current value
during the optimization process as well as other useful information.

A set of parameters are combined into a single :class: aido.SimulationParameterDictionary
which has extra tools. Most relevant is the way we interface the AIDO framework with your
simulation and reconstruction. For this, the dictionary is stored as a json file which
you can easily access in any programming language (for example C++ when using Geant4).
By inputting these values in your simulation, AIDO is able to optimize the parameters
automatically.

### aido.main.optimize(parameters, user_interface, simulation_tasks=1, max_iterations=50, threads=1, results_dir='./results/', description='', validation_tasks=0, \*\*kwargs)

* **Parameters:**
  * **parameters** (*List* *[**AIDO.parameter* *]*  *|* [*SimulationParameterDictionary*](#aido.simulation_helpers.SimulationParameterDictionary)) – Instance of a
    SimulationParameterDictionary with all the desired parameters. These are the starting parameters
    for the optimization loop and the outcome can depend on their starting values. Can also be a
    simple list of SimulationParameter / AIDO.parameters (the latter is a proxy method).
  * **user_interface** (*class* *or* *instance inherited from AIDOUserInterface*) – Regulates the interaction
    between user-defined code (simulation, reconstruction, merging of output files) and the
    AIDO workflow manager.
  * **simulation_tasks** (*int*) – Number of simulations started during each iteration.
  * **max_iterations** (*int*) – Maximum amount of iterations of the optimization loop
  * **threads** (*int*) – Allowed number of threads to allocate the simulation tasks.
    NOTE There is no benefit in having ‘threads’ > ‘simulation_tasks’ per se, but in some cases,
    errors involving missing dependencies after the simulation step can be fixed by setting:
    ‘threads’ = ‘simulation_tasks’ + 1.
  * **results_dir** (*str*) – Indicates where to save the results. Useful when differentiating runs from
    each other.
  * **description** (*str* *,* *optional*) – Additional text associated with the run. Is saved in the parameter
    json files under ‘metadata.description”
  * **validation_tasks** (*int*) – Control the number of simulation tasks dedicated only for validation
    purposes on top of the regular simulation tasks ‘simulation_tasks’. Defaults to ‘None’ which
    is no validation tasks. This will also disable the call of ‘interface.reconstruct’ with
    ‘is_validation=True’.
  * **kwargs** (*key-word arguments* *,* *optional*) – 

    Arguments to pass to ‘b2luigi.process’, such as
    > - show_output: bool = False
    > - dry_run: bool = False
    > - test: bool = False
    > - batch: bool = False
    > - ignore_additional_command_line_args: bool = False

    See the corresponding documentation at [https://b2luigi.readthedocs.io/en/stable/documentation/api.html](https://b2luigi.readthedocs.io/en/stable/documentation/api.html)

### aido.main.check_results_folder_format(directory)

Checks if the specified directory is of the ‘results’ format specified by AIDO.optimize().

* **Return type:**
  `bool`
* **Parameters:**
  **directory** (*str* *|* *os.PathLike*) – The path to the directory to check.
* **Returns:**
  bool
  : - True if the directory contains all the required folders
      > (“loss”, “models”, “parameters”, “plots”, “task_outputs”),
    - False otherwise.

### aido.main.set_config(key, value)

### aido.main.get_config(key)

* **Return type:**
  `Any`

## aido.optimization_helpers module

### *class* aido.optimization_helpers.OneHotEncoder(parameter)

Bases: `Module`

OneHotEncoder is a module that performs one-hot encoding on discrete values.

#### logits

A set of unnormalized, real-valued scores for each category. These logits
represent the model’s confidence in each category prior to normalization. They can take any
real value, including negatives, and are not probabilities themselves. Use the probabilities
property to convert the logits to probabilities.

* **Type:**
  torch.Tensor

TODO Restrict the learning rate of the logits since they converge much faster than Continuous parameters.

#### forward()

Passes the probabilities of each entry

* **Return type:**
  `Tensor`

#### *property* current_value *: Tensor*

Returns the probability Tensor

#### *property* physical_value *: Tensor*

Returns the value of the highest scoring entry

#### *property* probabilities *: Tensor*

Probabilities for each entry

#### *property* cost *: Tensor*

Costs associated to each entry

### *class* aido.optimization_helpers.ContinuousParameter(parameter)

Bases: `Module`

#### reset(parameter)

#### forward()

Define the computation performed at every call.

Should be overridden by all subclasses.
:rtype: `Tensor`

#### NOTE
Although the recipe for forward pass needs to be defined within
this function, one should call the `Module` instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.

#### *property* current_value *: Tensor*

#### *property* physical_value *: float*

#### *property* cost *: float*

### *class* aido.optimization_helpers.ParameterModule(parameter_dict)

Bases: `ModuleDict`

#### items()

Return an iterable of the ModuleDict key/value pairs.

* **Return type:**
  `Iterable`[`Tuple`[`str`, [`OneHotEncoder`](#aido.optimization_helpers.OneHotEncoder) | [`ContinuousParameter`](#aido.optimization_helpers.ContinuousParameter)]]

#### values()

Return an iterable of the ModuleDict values.

* **Return type:**
  `Iterable`[[`OneHotEncoder`](#aido.optimization_helpers.OneHotEncoder) | [`ContinuousParameter`](#aido.optimization_helpers.ContinuousParameter)]

#### forward()

Define the computation performed at every call.

Should be overridden by all subclasses.
:rtype: `Tensor`

#### NOTE
Although the recipe for forward pass needs to be defined within
this function, one should call the `Module` instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.

#### continuous_tensors()

* **Return type:**
  `Tensor`

#### current_values()

* **Return type:**
  `dict`

#### physical_values(format='list')

* **Return type:**
  `list` | `dict`

#### *property* probabilities *: dict[str, ndarray]*

#### *property* constraints *: Tensor*

A tensor of shape (P, 2) where P is the number of continuous parameters. In the second index,
the order is the same as in the ContinuousParameter class (min, max)

#### *property* cost_loss *: Tensor*

#### *property* covariance *: ndarray*

#### adjust_covariance(direction, min_scale=2.0)

Stretches the box_covariance of the generator in the directon specified as input.
Direction is a vector in parameter space

## aido.optimizer module

### *class* aido.optimizer.Optimizer(parameter_dict, device=None)

Bases: `Module`

The optimizer uses the surrogate model to optimise the detector parameters in batches.
It is also linked to a generator object, to check if the parameters are still in bounds using
the function is_local(parameters) of the generator.

Once the parameters are not local anymore, the optimizer will return the last parameters that were local and stop.
For this purpose, the surrogate model will need to be applied using fixed weights.
Then the reconstruction model loss will be applied based on the surrogate model output.
The gradient w.r.t. the detector parameters will be calculated and the parameters will be updated.

#### to(device, \*\*kwargs)

Move all Tensors and modules to ‘device’.

#### check_parameters_are_local(updated_parameters, scale=1.0)

Assure that the predicted parameters by the optimizer are within the bounds of the covariance
matrix spanned by the ‘sigma’ of each parameter.

* **Return type:**
  `bool`

#### boundaries()

Adds penalties for parameters that are outside of the boundaries spaned by ‘self.parameter_box’. This
ensures that the optimizer does not propose new values that are outside of the scope of the Surrogate and
therefore largely unknown to the current iteration.
Returns:
:rtype: `Tensor`

> float

#### other_constraints(constraints_func, parameter_dict_as_tensor)

Adds user-defined constraints defined in ‘interface.py:AIDOUserInterface.constraints()’. If no constraints
were added manually, this method defaults to calculating constraints based on the cost per parameter specified
in ParameterDict. Returns a float or torch.Tensor which can be considered as a penalty loss.

* **Return type:**
  `Tensor`

#### save_parameters(epoch, batch_index, loss, filepath='parameter_optimizer_df.parquet')

* **Return type:**
  `None`

#### print_grads()

* **Return type:**
  `None`

#### optimize(surrogate_model, dataset, batch_size, n_epochs, reconstruction_loss, additional_constraints=None, parameter_optimizer_savepath=None, device=None, lr=0.01)

Perform the optimization step.
:rtype: `Tuple`[[`SimulationParameterDictionary`](#aido.simulation_helpers.SimulationParameterDictionary), `bool`]

1. The ParameterModule().forward() method generates new parameters.
2. The Surrogate Model computes the corresponding Reconstruction Loss (based on its interpolation).
3. The Optimizer Loss is the Sum of the Reconstruction Loss, user-defined Parameter Loss
   : (e.g. cost constraints) and the Parameter Box Loss (which ensures that the Parameters stay
     within acceptable boundaries during training).
4. The optimizer applies backprogation and updates the current ParameterDict

### Return:

:
: SimulationParameterDictionary
  bool

#### *property* boosted_parameter_dict *: [SimulationParameterDictionary](#aido.simulation_helpers.SimulationParameterDictionary)*

Compute a new set of parameters by taking the current parameter dict and boosting it along
the direction of change between the previous and the current values (only continuous parameters).

Formula:
: [
  p_{n+1} = p_{opt} + frac{1}{2} left( p_{opt} - p_n right)
  ]
  <br/>
  Where:
  - ( p_{n+1} ) is the updated parameter dict.
  - ( p_{opt} ) is the current (optimized) parameter dict.
  - ( p_n ) is the starting parameter dict.

## aido.plotting module

### aido.plotting.percentage_type(value)

Checks if a float lies between [0, 1]

* **Return type:**
  `float`

### *class* aido.plotting.Plotting

Bases: `object`

#### *classmethod* plot(plot_types='all', results_dir='./results/')

Plot the evolution of variables of interest over the Optimization process.

* **Parameters:**
  **plot_types** (*str* *|* *List* *[**str* *]* *,* *optional*) – 

  The types of plots to be generated.
  It can be a string or a list of strings. If “all” is specified, it will
  generate all available plots. Available methods:
  > [“parameter_evolution”, “optimizer_loss”, “simulation_samples”]
* **Returns:**
  None

TODO Clean up this class and do not repeat the reading of files all the time

#### parameter_evolution(results_dir='./results/', parameter_dir='/parameters/')

Plots the evolution of all simulation parameters along with their respective “sigma”.

* **Return type:**
  `Tuple`[`DataFrame`, `ndarray`]
* **Parameters:**
  * **fig_savepath** (*str* *|* *os.PathLike* *,* *optional*) – The file path to save the figure.
    Defaults to “<results_dir>/plots/parameter_evolution”. If None, the figure will not be saved.
  * **results_dir** (*str* *|* *os.PathLike* *,* *optional*) – Results directory. Defaults to “./results/”
  * **parameter_dir** (*str* *|* *os.PathLike* *,* *optional*) – The directory path where the SimulationParameterDictionaries
    are stored (.json files). Defaults to “<results_dir>/parameters”.
* **Returns:**
  A Tuple containing the DataFrame with all parameters provided by the
  : optimizer after each iteration, and the simulation sampling standard deviation (2D array).
* **Return type:**
  Tuple(pd.DataFrame, np.ndarray)

#### optimizer_loss(results_dir='./results/', optimizer_loss_dir='/loss/optimizer')

* **Return type:**
  `DataFrame`

Plot the optimizer loss over epochs and save the figure if fig_savepath is provided.
:param fig_savepath: Path to save the figure. If None, the figure will not be saved.
:type fig_savepath: str | os.PathLike | None
:param results_dir: Results directory. Defaults to “./results/”
:type results_dir: str | os.PathLike, optional
:param optimizer_loss_dir: Directory containing the optimizer loss files.
:type optimizer_loss_dir: str | os.PathLike

* **Returns:**
  DataFrame with the optimizer loss at each iteration
* **Return type:**
  df_loss (pd.DataFrame)

#### simulation_samples(results_dir='./results/', parameter_dir='/parameters/', sampled_param_dict_filepath='/task_outputs/iteration=\*/validation=False')

* **Return type:**
  `Tuple`[`DataFrame`, `ndarray`]

Generate a DataFrame of simulation parameters and their values for each iteration and task.
:param fig_savepath: Path to save the generated plot.

> Defaults to “./results/plots/simulation_samples”.
* **Parameters:**
  * **sampled_param_dict_filepath** (*str* *|* *os.PathLike* *,* *optional*) – Path to the sampled parameter dictionary files.
    Defaults to “./results/task_outputs/simulation_task\*”.
  * **parameter_dir** (*str*) – Where the parameters are stored in the results folder. Defaults to ‘parametersÄ.
* **Returns:**
  A tuple containing the DataFrame of simulation parameters and a
  : numpy array of sigma values.
* **Return type:**
  Tuple(pd.DataFrame, np.ndarray)

TODO Check for the files in a dynamic way in case b2luigi changes the names of the directories
due to changes in the b2luigi.Parameters of the SimulationTasks.

#### probability_evolution(results_dir='./results/', parameter_dir='/parameters')

#### fwhm(y, height=0.5, ax=None)

Compute the FWHM of a (x, y) distribution
If x has one more item than y, the zeroth item of x will be skipped (useful for binned histograms)
Returns:
:rtype: `Union`[`Tuple`[`float`, `float`, `float`, `float`], `Axes`]

> If Axes is None:
> : fwhm (float): Full Width at Half Maximum (weighted by ‘height’ argument)
>   x_left (float): left x value
>   y_right (float): right y value
>   height_absolute (float): absolute height of y at fwhm point

> If Axes is given:
> : ax (plt.Axes): ax with added vlines for the left and right x values

TODO what if x is not monotone?

## aido.scheduler module

### *class* aido.scheduler.SimulationTask(\*args, \*\*kwargs)

Bases: `AIDOTask`

#### iteration *= <luigi.parameter.IntParameter object>*

#### simulation_task_id *= <luigi.parameter.IntParameter object>*

#### num_simulation_tasks *= <luigi.parameter.IntParameter object>*

#### num_validation_tasks *= <luigi.parameter.IntParameter object>*

#### start_param_dict_filepath *= <luigi.parameter.PathParameter object>*

#### results_dir *= <luigi.parameter.PathParameter object>*

#### requires()

The Tasks that this Task depends on.

A Task will only run if all of the Tasks that it requires are completed.
If your Task does not require any other Tasks, then you don’t need to
override this method. Otherwise, a subclass can override this method
to return a single Task, a list of Task instances, or a dict whose
values are Task instances.

See Task.requires

#### output()

The output that this Task produces.

The output of the Task determines if the Task needs to be run–the task
is considered finished iff the outputs all exist. Subclasses should
override this method to return a single `Target` or a list of
`Target` instances.

* **Return type:**
  `Generator`

Implementation note
: If running multiple workers, the output must be a resource that is accessible
  by all workers, such as a DFS or database. Otherwise, workers might compute
  the same output since they don’t see the work done by other workers.

See Task.output

#### run()

Workflow:
1. Generate a new set of parameters based on the previous iteration
2. Start geant4 simulations using the ‘interface.simulate’ method provided by the user

* **Return type:**
  `None`

### *class* aido.scheduler.ReconstructionTask(\*args, \*\*kwargs)

Bases: `AIDOTask`

#### iteration *= <luigi.parameter.IntParameter object>*

#### is_validation *= <b2luigi.core.parameter.BoolParameter object>*

#### num_simulation_tasks *= <luigi.parameter.IntParameter object>*

#### num_validation_tasks *= <luigi.parameter.IntParameter object>*

#### start_param_dict_filepath *= <luigi.parameter.PathParameter object>*

#### results_dir *= <luigi.parameter.PathParameter object>*

#### requires()

The Tasks that this Task depends on.

A Task will only run if all of the Tasks that it requires are completed.
If your Task does not require any other Tasks, then you don’t need to
override this method. Otherwise, a subclass can override this method
to return a single Task, a list of Task instances, or a dict whose
values are Task instances.

See Task.requires

* **Return type:**
  `Generator`

#### output()

Define the output files for the task based on the validation parameter.

* **Return type:**
  `Generator`

#### run()

Run the reconstruction process. The type of processing depends on the validation flag.

* **Return type:**
  `None`

### *class* aido.scheduler.OptimizationTask(\*args, \*\*kwargs)

Bases: `AIDOTask`

This Task requires n=’num_simulation_tasks’ of StartSimulationTask before running. If the output of
this Task exists, then it will be completely skipped.
When running, it calls the user-provided ‘interface.merge()’ and ‘interface.reconstruct’ methods. The
output of the later is passed to the Surrogate/Optimizer.

#### iteration *= <luigi.parameter.IntParameter object>*

#### num_simulation_tasks *= <luigi.parameter.IntParameter object>*

#### num_validation_tasks *= <luigi.parameter.IntParameter object>*

#### results_dir *= <luigi.parameter.PathParameter object>*

#### output()

The output that this Task produces.

The output of the Task determines if the Task needs to be run–the task
is considered finished iff the outputs all exist. Subclasses should
override this method to return a single `Target` or a list of
`Target` instances.

* **Return type:**
  `Generator`

Implementation note
: If running multiple workers, the output must be a resource that is accessible
  by all workers, such as a DFS or database. Otherwise, workers might compute
  the same output since they don’t see the work done by other workers.

See Task.output

#### requires()

Starts the Reconstruction Tasks for regular reconstruction and for validation (the latter only
if ‘num_validation_tasks’ > 0).

* **Return type:**
  `Generator`

#### create_reco_path_dict()

* **Return type:**
  `Dict`

#### run()

For each root file produced by the simulation Task, start a container with the reconstruction algorithm.
Afterwards, the parameter dictionary used to generate these results are also passed as output
Alternative container:
:rtype: `None`

> /cvmfs/unpacked.cern.ch/registry.hub.docker.com/cernml4reco/deepjetcore3:latest

Current parameter dict is the main parameter dict of this iteration that was used to generate the
: simulations. It is fed to the Reconstruction and Surrogate/Optimizer models as input

Updated parameter dict is the output of the optimizer and is saved as the parameter dict of the
: next iteration (becoming its current parameter)

Next parameter dict is the location of the next iteration’s parameter dict, if already exists, the
: whole Tasks is skipped. Otherwise, the updated parameter dict is saved in this location

### aido.scheduler.start_scheduler(parameters, user_interface, simulation_tasks, max_iterations, threads, results_dir, validation_tasks, \*\*kwargs)

## aido.simulation_helpers module

### *class* aido.simulation_helpers.SimulationParameter(name, starting_value, current_value=None, units=None, optimizable=True, min_value=None, max_value=None, sigma=None, sigma_mode=None, discrete_values=None, probabilities=None, cost=None)

Bases: `object`

Base class for all parameters used in the simulation

#### to_dict()

Convert to dictionary

Protected attributes are written to file as public attributes.

* **Return type:**
  `Dict`

#### *classmethod* from_dict(attribute_dict)

Create from dictionary

#### *property* current_value *: Any*

#### *property* optimizable *: bool*

#### *property* sigma *: float | None*

#### *property* probabilities *: List[float]*

#### *property* weighted_cost *: None | float*

### *class* aido.simulation_helpers.SimulationParameterDictionary(parameter_list=[])

Bases: `object`

Dictionary containing all the parameters used by the simulation.

Attributes:
parameter_list: List[Type[SimulationParameter]]
parameter_dict: Dict[str, Type[SimulationParameter]]

Provides simple methods to easily write and read with the json format. Instances of this
class have the following methods, with additional options listed in the method’s docstring

> 1. Accessing the information stored in the class:

> > - Indexing as a list (in the same order as given during instantiation) or as a dict
> >   : using the parameter’s ‘name’. Also usable with list or dict comprehension.
> > - ‘to_dict’ returns a dict with the parameters also in a dict format. Alternatively,
> >   : it returns a dict of ‘SimulationParameter’ (same as indexing this class by ‘name’)
> >     if you add the keyword argument ‘serialized=False’.
> > - ‘to_json’ will write all data from this class to a specified .json file in a dict
> >   : format.
> > - ‘to_df’ returns a pd.DataFrame of your parameters. More options are listed in the
> >   : method’s docstring.
> > - ‘get_current_values’ returns all the current values of each parameter in a list or
> >   : dict format.
> > - ‘get_probabilities’ returns a dict whose values are the probabilities of each
> >   : discrete parameter. More information about the usage of probabilities for one-hot
> >     encoded parameters is listed in the docstring of SimulationParameter.
> 1. Instantiating this class from other objects:

> > - ‘from_dict’ instantiates this class from a nested dict, where each entry is the dict
> >   : representation of a SimulationParameter (which has a similar method)
> > - ‘from_json’ instantiates this class from a json file. Specially useful in the combination
> >   : with ‘to_json’ to transfer this class between programs.
> 1. Changing the information stored:

> > - ‘update_current_values’ will change all the current values of the class provided a
> >   : simple dict [str, <update_value>].
> > - ‘update_probabilities’ does the same but with all the probabilities of the discrete
> >   : parameters of the class.
> > - ‘generate_new’ will return a new instance of this class with new current values for each
> >   : parameter
> 1. Properties:

> > - ‘covariance’ returns a diagonal matrix with the ‘sigma’ of every continuous parameter.
> > - ‘metadata’ returns additional information about this class such as its creation time,
> >   : the current iteration of the optimization process and user-defined descriptions.

#### to_dict(serialized=True)

Converts the parameter list to a dictionary.

* **Parameters:**
  **serialized** – 

  A boolean indicating whether to return a Dict of SimulationParameters or
  a Dict of Dict (by serializing each SimulationParameter in turn)
  If False, the SimulationParameter objects will be included as is. This is used by this class to allow
  > dictionary-style access to the individual parameters
* **Return type:**
  `Dict`[`str`, `Union`[[`SimulationParameter`](#aido.simulation_helpers.SimulationParameter), `Dict`]]
* **Returns:**
  A dictionary where the keys are the names of the SimulationParameter objects and the values are either
  the serialized dictionaries or the SimulationParameter objects themselves.

#### to_json(file_path)

Write the parameter list to a .json file

TODO Check for the existence of the file path or otherwise set as default to ../

#### to_df(df_length=1, include_non_optimizables=False, display_discrete='default', types='all', \*\*kwargs)

Convert parameter dictionary to a pd.DataFrame

* **Return type:**
  `DataFrame`
* **Parameters:**
  * **(****int****)** (*df_length*)
  * **(****bool****)** (*include_non_optimizables*) – df. Defaults to False.
  * **(****Literal****)** (*display_discrete*) – 
    - ‘default’: Simply write the current value of the Parameter (default)
    - ’as_probabilities’: Write the probability of each category (from the list of available
      : discrete parameter).
    - ’as_one_hot’:Write the current value as a one-hot encoded array. All categories are set
      : to zero except for the ‘current_value’ which is set to one.
        Ref. [https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html](https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html)
  * **(****str****)** (*types*) – all parameters, continuous only those with no ‘discrete_values’ and discrete only
    those with ‘discrete_values’.
  * **kwargs** (*Additional keyword arguments to be passed to the pd.DataFrame constructor.*)
* **Returns:**
  A pandas DataFrame containing the current parameter values.

#### get_current_values(format='dict', include_non_optimizables=False, display_discrete='default', types='all')

* **Return type:**
  `Union`[`List`, `Dict`]

#### get_probabilities()

* **Return type:**
  `dict`[`str`, `List`[`float`]]

#### update_current_values(current_values_parameter_dict)

#### update_probabilities(probabilities_dict)

#### *property* sigma_array *: ndarray*

Diagonal matrix with the standard deviation of each continuous parameter

#### *property* covariance *: ndarray*

Get the current covariance matrix. If no covariance was set, it defaults
to the ‘sigma_array’ squared (covariance matrix with no correlations).

#### *property* metadata *: Dict[str, int | str | List]*

#### *classmethod* from_dict(parameter_dict)

Create an instance from dictionary
TODO Make sure it is a serialized dict, not a dict of SimulationParameters

#### *classmethod* from_json(file_path)

Create an instance from a .json file

#### generate_new(rng_seed=None, discrete_index=None, scaling_factor=1.0)

Generates a new set of values for each parameter, bounded by specified minimum and maximum
values for float parameters. For discrete parameters, the new value is randomly chosen from
the list of allowed values.

### Args:

rng_seed (int | None): Optional seed for the random number generator. If an integer is provided,
: the random number generator is initialized with that seed to ensure reproducibility. If None,
  a pseudo-random seed is generated by numpy.random.default_rng()

discrete_index (int | None): Optional indexing of the discrete parameters catergories in order to
: ensure that a certain category is represented. If ‘discrete_index’ > len(parameter.discrete_values),
  a random sampling is uses. Otherwise the chosen value is parameter.discrete_values[‘discrete_index’]

## aido.surrogate module

### aido.surrogate.ddpm_schedules(beta1, beta2, n_time_steps)

Returns pre-computed schedules for DDPM sampling, training process.

* **Return type:**
  `dict`[`str`, `Tensor`]

### *class* aido.surrogate.NoiseAdder(n_time_steps, betas=(0.0001, 0.02))

Bases: `Module`

#### forward(x, t)

x: (B, C, H, W)
t: (B, 1)
z: (B, C, H, W)
x_t: (B, C, H, W)

### *class* aido.surrogate.SurrogateDataset(input_df, parameter_key='Parameters', context_key='Context', target_key='Targets', reconstructed_key='Reconstructed', device='cpu', means=None, stds=None, normalise_parameters=False)

Bases: `Dataset`

Dataset class for the Surrogate model

### Args:

> df (pd.DataFrame): A DataFrame containing the following keys:

> > [“Parameters”, “Context”, “Loss”]

TODO: Accommodate for discrete parameters

#### filter_infs_and_nans(df)

Removes all events that contain infs or nans.

* **Return type:**
  `DataFrame`

#### unnormalise_features(target, index)

* **Return type:**
  `Tensor` | `ndarray`

Return the physically meaningful target from the normalised target
Index:

> 0 -> Parameters
> 1 -> Context
> 2 -> Targets

#### normalise_features(target, index)

* **Return type:**
  `Tensor` | `ndarray`

Normalize a feature
Index:

> 0 -> Parameters
> 1 -> Context
> 2 -> Targets

### *class* aido.surrogate.Surrogate(num_parameters, num_context, num_targets, num_reconstructed, initial_means, initial_stds, n_time_steps=50, betas=(0.0001, 0.02))

Bases: `Module`

Surrogate model class and the surrogate model training function, given a dataset consisting of events.
The surrogate model itself can be very simple. It is just a feed-forward model but used as a diffusion model.

#### betas

Tuple containing the start and end beta values for the diffusion process.

* **Type:**
  Tuple[float]

#### t_is

Tensor containing time steps normalized by the number of time steps.

* **Type:**
  torch.Tensor

#### forward(parameters, context, reconstructed, time_step)

Forward pass of the model. Concatenates the input features and passes them through the network.

#### to(device=None)

Moves the model and its buffers to the specified device.

#### create_noisy_input(x)

Adds noise to a tensor for the diffusion process.

#### sample_forward(parameters, context)

Samples from the model in a forward pass using the diffusion process.

#### train_model(surrogate_dataset, batch_size, n_epochs, lr)

Trains the surrogate diffusion model using the provided dataset.

#### apply_model_in_batches(dataset, batch_size, oversample=1)

Applies the model to the dataset in batches and returns the results.

#### forward(parameters, context, targets, reconstructed, time_step)

When sampling forward, ‘parameters’ has only one entry, therefore it is broadcast to
the shape of ‘context’.

#### to(device=None)

Move and/or cast the parameters and buffers.

This can be called as

#### to(device=None, dtype=None, non_blocking=False)

#### to(dtype, non_blocking=False)

#### to(tensor, non_blocking=False)

#### to(memory_format=torch.channels_last)

Its signature is similar to `torch.Tensor.to()`, but only accepts
floating point or complex `dtype`s. In addition, this method will
only cast the floating point or complex parameters and buffers to `dtype`
(if given). The integral parameters and buffers will be moved
`device`, if that is given, but with dtypes unchanged. When
`non_blocking` is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.

See below for examples.

#### NOTE
This method modifies the module in-place.

* **Parameters:**
  * **device** (`torch.device`) – the desired device of the parameters
    and buffers in this module
  * **dtype** (`torch.dtype`) – the desired floating point or complex dtype of
    the parameters and buffers in this module
  * **tensor** (*torch.Tensor*) – Tensor whose dtype and device are the desired
    dtype and device for all parameters and buffers in this module
  * **memory_format** (`torch.memory_format`) – the desired memory
    format for 4D parameters and buffers in this module (keyword
    only argument)
* **Returns:**
  self
* **Return type:**
  Module

Examples:

```default
>>> # xdoctest: +IGNORE_WANT("non-deterministic")
>>> linear = nn.Linear(2, 2)
>>> linear.weight
Parameter containing:
tensor([[ 0.1913, -0.3420],
        [-0.5113, -0.2325]])
>>> linear.to(torch.double)
Linear(in_features=2, out_features=2, bias=True)
>>> linear.weight
Parameter containing:
tensor([[ 0.1913, -0.3420],
        [-0.5113, -0.2325]], dtype=torch.float64)
>>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)
>>> gpu1 = torch.device("cuda:1")
>>> linear.to(gpu1, dtype=torch.half, non_blocking=True)
Linear(in_features=2, out_features=2, bias=True)
>>> linear.weight
Parameter containing:
tensor([[ 0.1914, -0.3420],
        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')
>>> cpu = torch.device("cpu")
>>> linear.to(cpu)
Linear(in_features=2, out_features=2, bias=True)
>>> linear.weight
Parameter containing:
tensor([[ 0.1914, -0.3420],
        [-0.5112, -0.2324]], dtype=torch.float16)

>>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)
>>> linear.weight
Parameter containing:
tensor([[ 0.3741+0.j,  0.2382+0.j],
        [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)
>>> linear(torch.ones(3, 2, dtype=torch.cdouble))
tensor([[0.6122+0.j, 0.1150+0.j],
        [0.6122+0.j, 0.1150+0.j],
        [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)
```

#### update_best_surrogate_loss(loss)

* **Return type:**
  `bool`

#### create_noisy_input(x, scale=1.0)

Add gaussian noise to a tensor. Scale the noise with ‘scale’, by default the noise is N(0, 1).

* **Return type:**
  `Tuple`[`Tensor`, `Tensor`, `Tensor`]
* **Parameters:**
  **x** (*torch.Tensor*) – The input tensor to which noise will be added.
* **Returns:**
  A tuple containing:
  : - torch.Tensor: The noisy tensor.
    - torch.Tensor: The noise added to the input tensor.
    - torch.Tensor: The time steps used for generating the noise.
* **Return type:**
  tuple

#### sample_forward(parameters, context, targets)

* **Return type:**
  `Tensor`

#### train_model(surrogate_dataset, batch_size, n_epochs, lr)

Train the Surrogate Diffusion model. The training loop includes the added
noise.

* **Return type:**
  `float`

#### apply_model_in_batches(dataset, batch_size, oversample=1)

Applies the model to the given dataset in batches and returns the results.

* **Parameters:**
  * **dataset** ([*SurrogateDataset*](#aido.surrogate.SurrogateDataset)) – The dataset to apply the model to.
  * **batch_size** (*int*) – The size of each batch.
  * **oversample** (*int* *,* *optional*) – The number of times to oversample the dataset. Default is 1.
* **Returns:**
  A tuple containing three elements:
  : - results (torch.Tensor): The surrogate model’s predictions.
* **Return type:**
  tuple

Remarks: In most cases the resulting Tensor with sampled Data is not of importance, only the
: model weights.

## aido.surrogate_validation module

## aido.training module

### aido.training.pre_train(model, dataset, n_epochs)

Pre-train the Surrogate Model.

TODO Reconstruction results are normalized. In the future only expose the un-normalised ones,
but also requires adjustments to the surrogate dataset

### aido.training.training_loop(reco_file_paths_dict, reconstruction_loss_function, constraints=None)

## Module contents

### aido.optimize(parameters, user_interface, simulation_tasks=1, max_iterations=50, threads=1, results_dir='./results/', description='', validation_tasks=0, \*\*kwargs)

* **Parameters:**
  * **parameters** (*List* *[**AIDO.parameter* *]*  *|* [*SimulationParameterDictionary*](#aido.SimulationParameterDictionary)) – Instance of a
    SimulationParameterDictionary with all the desired parameters. These are the starting parameters
    for the optimization loop and the outcome can depend on their starting values. Can also be a
    simple list of SimulationParameter / AIDO.parameters (the latter is a proxy method).
  * **user_interface** (*class* *or* *instance inherited from AIDOUserInterface*) – Regulates the interaction
    between user-defined code (simulation, reconstruction, merging of output files) and the
    AIDO workflow manager.
  * **simulation_tasks** (*int*) – Number of simulations started during each iteration.
  * **max_iterations** (*int*) – Maximum amount of iterations of the optimization loop
  * **threads** (*int*) – Allowed number of threads to allocate the simulation tasks.
    NOTE There is no benefit in having ‘threads’ > ‘simulation_tasks’ per se, but in some cases,
    errors involving missing dependencies after the simulation step can be fixed by setting:
    ‘threads’ = ‘simulation_tasks’ + 1.
  * **results_dir** (*str*) – Indicates where to save the results. Useful when differentiating runs from
    each other.
  * **description** (*str* *,* *optional*) – Additional text associated with the run. Is saved in the parameter
    json files under ‘metadata.description”
  * **validation_tasks** (*int*) – Control the number of simulation tasks dedicated only for validation
    purposes on top of the regular simulation tasks ‘simulation_tasks’. Defaults to ‘None’ which
    is no validation tasks. This will also disable the call of ‘interface.reconstruct’ with
    ‘is_validation=True’.
  * **kwargs** (*key-word arguments* *,* *optional*) – 

    Arguments to pass to ‘b2luigi.process’, such as
    > - show_output: bool = False
    > - dry_run: bool = False
    > - test: bool = False
    > - batch: bool = False
    > - ignore_additional_command_line_args: bool = False

    See the corresponding documentation at [https://b2luigi.readthedocs.io/en/stable/documentation/api.html](https://b2luigi.readthedocs.io/en/stable/documentation/api.html)

### *class* aido.SimulationParameter(name, starting_value, current_value=None, units=None, optimizable=True, min_value=None, max_value=None, sigma=None, sigma_mode=None, discrete_values=None, probabilities=None, cost=None)

Bases: `object`

Base class for all parameters used in the simulation

#### to_dict()

Convert to dictionary

Protected attributes are written to file as public attributes.

* **Return type:**
  `Dict`

#### *classmethod* from_dict(attribute_dict)

Create from dictionary

#### *property* current_value *: Any*

#### *property* optimizable *: bool*

#### *property* sigma *: float | None*

#### *property* probabilities *: List[float]*

#### *property* weighted_cost *: None | float*

### *class* aido.SimulationParameterDictionary(parameter_list=[])

Bases: `object`

Dictionary containing all the parameters used by the simulation.

Attributes:
parameter_list: List[Type[SimulationParameter]]
parameter_dict: Dict[str, Type[SimulationParameter]]

Provides simple methods to easily write and read with the json format. Instances of this
class have the following methods, with additional options listed in the method’s docstring

> 1. Accessing the information stored in the class:

> > - Indexing as a list (in the same order as given during instantiation) or as a dict
> >   : using the parameter’s ‘name’. Also usable with list or dict comprehension.
> > - ‘to_dict’ returns a dict with the parameters also in a dict format. Alternatively,
> >   : it returns a dict of ‘SimulationParameter’ (same as indexing this class by ‘name’)
> >     if you add the keyword argument ‘serialized=False’.
> > - ‘to_json’ will write all data from this class to a specified .json file in a dict
> >   : format.
> > - ‘to_df’ returns a pd.DataFrame of your parameters. More options are listed in the
> >   : method’s docstring.
> > - ‘get_current_values’ returns all the current values of each parameter in a list or
> >   : dict format.
> > - ‘get_probabilities’ returns a dict whose values are the probabilities of each
> >   : discrete parameter. More information about the usage of probabilities for one-hot
> >     encoded parameters is listed in the docstring of SimulationParameter.
> 1. Instantiating this class from other objects:

> > - ‘from_dict’ instantiates this class from a nested dict, where each entry is the dict
> >   : representation of a SimulationParameter (which has a similar method)
> > - ‘from_json’ instantiates this class from a json file. Specially useful in the combination
> >   : with ‘to_json’ to transfer this class between programs.
> 1. Changing the information stored:

> > - ‘update_current_values’ will change all the current values of the class provided a
> >   : simple dict [str, <update_value>].
> > - ‘update_probabilities’ does the same but with all the probabilities of the discrete
> >   : parameters of the class.
> > - ‘generate_new’ will return a new instance of this class with new current values for each
> >   : parameter
> 1. Properties:

> > - ‘covariance’ returns a diagonal matrix with the ‘sigma’ of every continuous parameter.
> > - ‘metadata’ returns additional information about this class such as its creation time,
> >   : the current iteration of the optimization process and user-defined descriptions.

#### to_dict(serialized=True)

Converts the parameter list to a dictionary.

* **Parameters:**
  **serialized** – 

  A boolean indicating whether to return a Dict of SimulationParameters or
  a Dict of Dict (by serializing each SimulationParameter in turn)
  If False, the SimulationParameter objects will be included as is. This is used by this class to allow
  > dictionary-style access to the individual parameters
* **Return type:**
  `Dict`[`str`, `Union`[[`SimulationParameter`](#aido.simulation_helpers.SimulationParameter), `Dict`]]
* **Returns:**
  A dictionary where the keys are the names of the SimulationParameter objects and the values are either
  the serialized dictionaries or the SimulationParameter objects themselves.

#### to_json(file_path)

Write the parameter list to a .json file

TODO Check for the existence of the file path or otherwise set as default to ../

#### to_df(df_length=1, include_non_optimizables=False, display_discrete='default', types='all', \*\*kwargs)

Convert parameter dictionary to a pd.DataFrame

* **Return type:**
  `DataFrame`
* **Parameters:**
  * **(****int****)** (*df_length*)
  * **(****bool****)** (*include_non_optimizables*) – df. Defaults to False.
  * **(****Literal****)** (*display_discrete*) – 
    - ‘default’: Simply write the current value of the Parameter (default)
    - ’as_probabilities’: Write the probability of each category (from the list of available
      : discrete parameter).
    - ’as_one_hot’:Write the current value as a one-hot encoded array. All categories are set
      : to zero except for the ‘current_value’ which is set to one.
        Ref. [https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html](https://pytorch.org/docs/stable/generated/torch.nn.functional.one_hot.html)
  * **(****str****)** (*types*) – all parameters, continuous only those with no ‘discrete_values’ and discrete only
    those with ‘discrete_values’.
  * **kwargs** (*Additional keyword arguments to be passed to the pd.DataFrame constructor.*)
* **Returns:**
  A pandas DataFrame containing the current parameter values.

#### get_current_values(format='dict', include_non_optimizables=False, display_discrete='default', types='all')

* **Return type:**
  `Union`[`List`, `Dict`]

#### get_probabilities()

* **Return type:**
  `dict`[`str`, `List`[`float`]]

#### update_current_values(current_values_parameter_dict)

#### update_probabilities(probabilities_dict)

#### *property* sigma_array *: ndarray*

Diagonal matrix with the standard deviation of each continuous parameter

#### *property* covariance *: ndarray*

Get the current covariance matrix. If no covariance was set, it defaults
to the ‘sigma_array’ squared (covariance matrix with no correlations).

#### *property* metadata *: Dict[str, int | str | List]*

#### *classmethod* from_dict(parameter_dict)

Create an instance from dictionary
TODO Make sure it is a serialized dict, not a dict of SimulationParameters

#### *classmethod* from_json(file_path)

Create an instance from a .json file

#### generate_new(rng_seed=None, discrete_index=None, scaling_factor=1.0)

Generates a new set of values for each parameter, bounded by specified minimum and maximum
values for float parameters. For discrete parameters, the new value is randomly chosen from
the list of allowed values.

### Args:

rng_seed (int | None): Optional seed for the random number generator. If an integer is provided,
: the random number generator is initialized with that seed to ensure reproducibility. If None,
  a pseudo-random seed is generated by numpy.random.default_rng()

discrete_index (int | None): Optional indexing of the discrete parameters catergories in order to
: ensure that a certain category is represented. If ‘discrete_index’ > len(parameter.discrete_values),
  a random sampling is uses. Otherwise the chosen value is parameter.discrete_values[‘discrete_index’]

### aido.check_results_folder_format(directory)

Checks if the specified directory is of the ‘results’ format specified by AIDO.optimize().

* **Return type:**
  `bool`
* **Parameters:**
  **directory** (*str* *|* *os.PathLike*) – The path to the directory to check.
* **Returns:**
  bool
  : - True if the directory contains all the required folders
      > (“loss”, “models”, “parameters”, “plots”, “task_outputs”),
    - False otherwise.

### aido.set_config(key, value)

### aido.get_config(key)

* **Return type:**
  `Any`

### *class* aido.UserInterfaceBase

Bases: `_UserInterfaceBase`

#### *abstract* simulate(parameter_dict_path, sim_output_path)

This method must be implemented

Starts the simulation process. We recommend starting a container and passing the arguments
from the command line.

Open the parameter dict using:
:rtype: `None`

> parameter_dict = json.load(parameter_dict_path)

Access its items by name and the key ‘current_value’:

> foo_value = parameter_dict[“foo”][“current_value]

The simulation should output exactly one file, which must be saved at ‘sim_output_path’. You
are free to choose the output format of the simulation (e.g. root file)

* **Parameters:**
  * **parameter_dict_path** (*str*) – The path to the parameter dictionary file.
  * **sim_output_path** (*str*) – The path to save the simulation output.

#### *abstract* merge(parameter_dict_file_paths, simulation_file_paths, reco_input_path)

This method must be implemented

This method must merge the parameter dicts and the simulation outputs into a single file.
Its file path will be passed by the scheduler to the ‘reconstruct’ method as the first
argument (‘reco_input_path’). You are free to choose the file format of ‘reco_input_path’.

* **Return type:**
  `None`
* **Parameters:**
  * **parameter_dict_file_paths** (*List* *[**str* *]*) – List of the simulation parameter dictionary paths
  * **simulation_file_paths** (*List* *[**str* *]*) – List of the simulation output paths
  * **reco_input_path** (*str*) – Path for the merged file created by this method.

#### *abstract* reconstruct(reco_input_path, reco_output_path, is_validation=False)

This method must be implemented

Start your reconstruction algorithm here. We recommend using a container and starting the
reconstruction from the command line.

* **Return type:**
  `None`
* **Parameters:**
  * **reco_input_path** (*str*) – Path of the input file for your reconstruction process. It is the same
    path as the output of the ‘merge’ method.
  * **reco_output_path** (*str*) – Path of the output file generated by your reconstruction process. Since
    this file interfaces with the AIDO Optimizer, it must have a specific format detailed in the
    following.
  * **is_validation** (*bool*) – Useful to define a distinct behavior for regular reconstruction and for
    evaluation.

Output file format (IMPORTANT):
: The output file generated by this method must be a parquet file of a pandas.DataFrame.

#### constraints(parameter_dict, parameter_dict_as_tensor)

This method is optional

Use this method to compute additional constraints such as cost or dimensions using pytorch. The resulting
Tensor must be one-dimensional and include gradients.

* **Return type:**
  `None` | `Tensor`

#### plot(parameter_dict)

This method is optional

Use this method to execute code after each iteration. This can be anything used to track the
progress of the Optimization process.

* **Return type:**
  `None`

#### loss(y, y_pred)

This method is optional

Use this method to compute the loss of the internal Optimizer. This must be an equivalent
implementation to your reconstruction loss.

* **Return type:**
  `Tensor`

### *class* aido.Plotting

Bases: `object`

#### *classmethod* plot(plot_types='all', results_dir='./results/')

Plot the evolution of variables of interest over the Optimization process.

* **Parameters:**
  **plot_types** (*str* *|* *List* *[**str* *]* *,* *optional*) – 

  The types of plots to be generated.
  It can be a string or a list of strings. If “all” is specified, it will
  generate all available plots. Available methods:
  > [“parameter_evolution”, “optimizer_loss”, “simulation_samples”]
* **Returns:**
  None

TODO Clean up this class and do not repeat the reading of files all the time

#### parameter_evolution(results_dir='./results/', parameter_dir='/parameters/')

Plots the evolution of all simulation parameters along with their respective “sigma”.

* **Return type:**
  `Tuple`[`DataFrame`, `ndarray`]
* **Parameters:**
  * **fig_savepath** (*str* *|* *os.PathLike* *,* *optional*) – The file path to save the figure.
    Defaults to “<results_dir>/plots/parameter_evolution”. If None, the figure will not be saved.
  * **results_dir** (*str* *|* *os.PathLike* *,* *optional*) – Results directory. Defaults to “./results/”
  * **parameter_dir** (*str* *|* *os.PathLike* *,* *optional*) – The directory path where the SimulationParameterDictionaries
    are stored (.json files). Defaults to “<results_dir>/parameters”.
* **Returns:**
  A Tuple containing the DataFrame with all parameters provided by the
  : optimizer after each iteration, and the simulation sampling standard deviation (2D array).
* **Return type:**
  Tuple(pd.DataFrame, np.ndarray)

#### optimizer_loss(results_dir='./results/', optimizer_loss_dir='/loss/optimizer')

* **Return type:**
  `DataFrame`

Plot the optimizer loss over epochs and save the figure if fig_savepath is provided.
:param fig_savepath: Path to save the figure. If None, the figure will not be saved.
:type fig_savepath: str | os.PathLike | None
:param results_dir: Results directory. Defaults to “./results/”
:type results_dir: str | os.PathLike, optional
:param optimizer_loss_dir: Directory containing the optimizer loss files.
:type optimizer_loss_dir: str | os.PathLike

* **Returns:**
  DataFrame with the optimizer loss at each iteration
* **Return type:**
  df_loss (pd.DataFrame)

#### simulation_samples(results_dir='./results/', parameter_dir='/parameters/', sampled_param_dict_filepath='/task_outputs/iteration=\*/validation=False')

* **Return type:**
  `Tuple`[`DataFrame`, `ndarray`]

Generate a DataFrame of simulation parameters and their values for each iteration and task.
:param fig_savepath: Path to save the generated plot.

> Defaults to “./results/plots/simulation_samples”.
* **Parameters:**
  * **sampled_param_dict_filepath** (*str* *|* *os.PathLike* *,* *optional*) – Path to the sampled parameter dictionary files.
    Defaults to “./results/task_outputs/simulation_task\*”.
  * **parameter_dir** (*str*) – Where the parameters are stored in the results folder. Defaults to ‘parametersÄ.
* **Returns:**
  A tuple containing the DataFrame of simulation parameters and a
  : numpy array of sigma values.
* **Return type:**
  Tuple(pd.DataFrame, np.ndarray)

TODO Check for the files in a dynamic way in case b2luigi changes the names of the directories
due to changes in the b2luigi.Parameters of the SimulationTasks.

#### probability_evolution(results_dir='./results/', parameter_dir='/parameters')

#### fwhm(y, height=0.5, ax=None)

Compute the FWHM of a (x, y) distribution
If x has one more item than y, the zeroth item of x will be skipped (useful for binned histograms)
Returns:
:rtype: `Union`[`Tuple`[`float`, `float`, `float`, `float`], `Axes`]

> If Axes is None:
> : fwhm (float): Full Width at Half Maximum (weighted by ‘height’ argument)
>   x_left (float): left x value
>   y_right (float): right y value
>   height_absolute (float): absolute height of y at fwhm point

> If Axes is given:
> : ax (plt.Axes): ax with added vlines for the left and right x values

TODO what if x is not monotone?

### *class* aido.Surrogate(num_parameters, num_context, num_targets, num_reconstructed, initial_means, initial_stds, n_time_steps=50, betas=(0.0001, 0.02))

Bases: `Module`

Surrogate model class and the surrogate model training function, given a dataset consisting of events.
The surrogate model itself can be very simple. It is just a feed-forward model but used as a diffusion model.

#### betas

Tuple containing the start and end beta values for the diffusion process.

* **Type:**
  Tuple[float]

#### t_is

Tensor containing time steps normalized by the number of time steps.

* **Type:**
  torch.Tensor

#### forward(parameters, context, reconstructed, time_step)

Forward pass of the model. Concatenates the input features and passes them through the network.

#### to(device=None)

Moves the model and its buffers to the specified device.

#### create_noisy_input(x)

Adds noise to a tensor for the diffusion process.

#### sample_forward(parameters, context)

Samples from the model in a forward pass using the diffusion process.

#### train_model(surrogate_dataset, batch_size, n_epochs, lr)

Trains the surrogate diffusion model using the provided dataset.

#### apply_model_in_batches(dataset, batch_size, oversample=1)

Applies the model to the dataset in batches and returns the results.

#### forward(parameters, context, targets, reconstructed, time_step)

When sampling forward, ‘parameters’ has only one entry, therefore it is broadcast to
the shape of ‘context’.

#### to(device=None)

Move and/or cast the parameters and buffers.

This can be called as

#### to(device=None, dtype=None, non_blocking=False)

#### to(dtype, non_blocking=False)

#### to(tensor, non_blocking=False)

#### to(memory_format=torch.channels_last)

Its signature is similar to `torch.Tensor.to()`, but only accepts
floating point or complex `dtype`s. In addition, this method will
only cast the floating point or complex parameters and buffers to `dtype`
(if given). The integral parameters and buffers will be moved
`device`, if that is given, but with dtypes unchanged. When
`non_blocking` is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.

See below for examples.

#### NOTE
This method modifies the module in-place.

* **Parameters:**
  * **device** (`torch.device`) – the desired device of the parameters
    and buffers in this module
  * **dtype** (`torch.dtype`) – the desired floating point or complex dtype of
    the parameters and buffers in this module
  * **tensor** (*torch.Tensor*) – Tensor whose dtype and device are the desired
    dtype and device for all parameters and buffers in this module
  * **memory_format** (`torch.memory_format`) – the desired memory
    format for 4D parameters and buffers in this module (keyword
    only argument)
* **Returns:**
  self
* **Return type:**
  Module

Examples:

```default
>>> # xdoctest: +IGNORE_WANT("non-deterministic")
>>> linear = nn.Linear(2, 2)
>>> linear.weight
Parameter containing:
tensor([[ 0.1913, -0.3420],
        [-0.5113, -0.2325]])
>>> linear.to(torch.double)
Linear(in_features=2, out_features=2, bias=True)
>>> linear.weight
Parameter containing:
tensor([[ 0.1913, -0.3420],
        [-0.5113, -0.2325]], dtype=torch.float64)
>>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)
>>> gpu1 = torch.device("cuda:1")
>>> linear.to(gpu1, dtype=torch.half, non_blocking=True)
Linear(in_features=2, out_features=2, bias=True)
>>> linear.weight
Parameter containing:
tensor([[ 0.1914, -0.3420],
        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')
>>> cpu = torch.device("cpu")
>>> linear.to(cpu)
Linear(in_features=2, out_features=2, bias=True)
>>> linear.weight
Parameter containing:
tensor([[ 0.1914, -0.3420],
        [-0.5112, -0.2324]], dtype=torch.float16)

>>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)
>>> linear.weight
Parameter containing:
tensor([[ 0.3741+0.j,  0.2382+0.j],
        [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)
>>> linear(torch.ones(3, 2, dtype=torch.cdouble))
tensor([[0.6122+0.j, 0.1150+0.j],
        [0.6122+0.j, 0.1150+0.j],
        [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)
```

#### update_best_surrogate_loss(loss)

* **Return type:**
  `bool`

#### create_noisy_input(x, scale=1.0)

Add gaussian noise to a tensor. Scale the noise with ‘scale’, by default the noise is N(0, 1).

* **Return type:**
  `Tuple`[`Tensor`, `Tensor`, `Tensor`]
* **Parameters:**
  **x** (*torch.Tensor*) – The input tensor to which noise will be added.
* **Returns:**
  A tuple containing:
  : - torch.Tensor: The noisy tensor.
    - torch.Tensor: The noise added to the input tensor.
    - torch.Tensor: The time steps used for generating the noise.
* **Return type:**
  tuple

#### sample_forward(parameters, context, targets)

* **Return type:**
  `Tensor`

#### train_model(surrogate_dataset, batch_size, n_epochs, lr)

Train the Surrogate Diffusion model. The training loop includes the added
noise.

* **Return type:**
  `float`

#### apply_model_in_batches(dataset, batch_size, oversample=1)

Applies the model to the given dataset in batches and returns the results.

* **Parameters:**
  * **dataset** ([*SurrogateDataset*](#aido.SurrogateDataset)) – The dataset to apply the model to.
  * **batch_size** (*int*) – The size of each batch.
  * **oversample** (*int* *,* *optional*) – The number of times to oversample the dataset. Default is 1.
* **Returns:**
  A tuple containing three elements:
  : - results (torch.Tensor): The surrogate model’s predictions.
* **Return type:**
  tuple

Remarks: In most cases the resulting Tensor with sampled Data is not of importance, only the
: model weights.

### *class* aido.SurrogateDataset(input_df, parameter_key='Parameters', context_key='Context', target_key='Targets', reconstructed_key='Reconstructed', device='cpu', means=None, stds=None, normalise_parameters=False)

Bases: `Dataset`

Dataset class for the Surrogate model

### Args:

> df (pd.DataFrame): A DataFrame containing the following keys:

> > [“Parameters”, “Context”, “Loss”]

TODO: Accommodate for discrete parameters

#### filter_infs_and_nans(df)

Removes all events that contain infs or nans.

* **Return type:**
  `DataFrame`

#### unnormalise_features(target, index)

* **Return type:**
  `Tensor` | `ndarray`

Return the physically meaningful target from the normalised target
Index:

> 0 -> Parameters
> 1 -> Context
> 2 -> Targets

#### normalise_features(target, index)

* **Return type:**
  `Tensor` | `ndarray`

Normalize a feature
Index:

> 0 -> Parameters
> 1 -> Context
> 2 -> Targets
